<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-size: 32px;
    font-weight: 300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  a:link,
  a:visited {
    color: #1367a7;
    text-decoration: none;
  }

  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35),
      /* The third layer shadow */
      15px 15px 0 0px #fff,
      /* The fourth layer */
      15px 15px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fourth layer shadow */
      20px 20px 0 0px #fff,
      /* The fifth layer */
      20px 20px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fifth layer shadow */
      25px 25px 0 0px #fff,
      /* The fifth layer */
      25px 25px 1px 1px rgba(0, 0, 0, 0.35);
    /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }

  .paper-big {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35);
    /* The top layer shadow */

    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35);
    /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
    top: 50%;
    transform: translateY(-50%);
  }

  hr {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

<html>

<head>
  <title>Spiking Neural Networks for Fast-Moving Object Detection on Neuromorphic Hardware Devices Using an Event-Based Camera</title>
  <meta property="og:image" content="Path to my teaser.png" />
  <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
  <meta property="og:title" content="Spiking Neural Networks for Fast-Moving Object Detection on Neuromorphic Hardware Devices Using an Event-Based Camera" />
  <meta property="og:description" content="Paper description." />

  <!-- Get from Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src=""></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-75863369-6');
  </script>
</head>

<body>
  <br>
  <center>
    <span style="font-size:36px">Spiking Neural Networks for Fast-Moving Object Detection on Neuromorphic Hardware Devices Using an Event-Based Camera</span>
    <table align=center width=990px>
      <table align=center width=990px>
        <tr>
          <td align=center width=110px>
            <center>
              <span style="font-size:24px"><a href="https://andreasaziegler.github.io/">Andreas Ziegler</a></span>
            </center>
          </td>
          <td align=center width=110px>
            <center>
              <span style="font-size:24px">Karl Vetter</span>
            </center>
          </td>
          <td align=center width=110px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/de/226101">Thomas Gossard</a></span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/de/138688">Jonas Tebbe</a></span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:24px"><a href="https://uni-tuebingen.de/de/138703">Andreas Zell</a></span>
            </center>
          </td>
        </tr>
      </table>
      <!--<table align=center width=990px>
        <span style="font-size:24px">*equal contribution</span>
      </table>-->
      <table align=center width=250px>
        <tr>
          <td align=center width=120px>
            <center>
              <span style="font-size:24px"><a href='https://arxiv.org/pdf/2403.10677'>[Paper]</a></span>
            </center>
          </td>
          <td align=center width=120px>
            <center>
							<span style="font-size:24px"><a href='https://github.com/cogsys-tuebingen/snn-edge-benchmark'> [Code]</a></span><br>
            </center>
          </td>
          <td align=center width=120px>
            <center>
							<span style="font-size:24px"><a href='https://github.com/cogsys-tuebingen/snn-edge-benchmark'> [Dataset]</a></span><br>
            </center>
          </td>
        </tr>
      </table>
    </table>
  </center>

  <center>
    <table align=center width=850px>
      <tr>
        <td width=260px>
          <center>
            <img class="round" style="width:600px" src="./resources/teaser.png" />
          </center>
        </td>
      </tr>
    </table>
    <table align=center width=850px>
      <tr>
        <td>
          <center>
            <i>Five observed 2D trajectories in the camera frame of the event-based camera with <font color="green">ground truth in green</font> and the <font color="red">estimated positions in red</font>.</i>
          </center>
        </td>
      </tr>
    </table>
  </center>

  <hr>

  <table align=center width=850px>
    <center>
      <h1>Abstract</h1>
    </center>
    <tr>
      <td>
          Table tennis is a fast-paced and exhilarating sport that demands agility, precision, and fast reflexes. In recent years, robotic table tennis has become a popular research challenge for robot perception algorithms. Fast and accurate ball detection is crucial for enabling a robotic arm to rally the ball back successfully. Previous approaches have employed conventional frame-based cameras with CNN or traditional computer vision methods. In this paper, we propose a novel solution that combines an event-based camera with Spiking Neural Network (SNN) for ball detection. We use multiple state-of-the-art SNN frameworks and develop a SNN architecture for each of them, complying with their corresponding limitations. Additionally, we implement the SNN solution across multiple neuromorphic edge devices, conducting comparisons of their accuracies and run-times. This furnishes robotics researchers with a benchmark illustrating the capabilities achievable with each SNN framework and a corresponding neuromorphic edge device. Next to this comparison of SNN solutions for robots, we also show that an SNN on a neuromorphic edge device is able to run in real-time in a closed loop robotic system, a table tennis robot in our use case.
      </td>
    </tr>
  </table>
  <br>

  <hr>
  <center>
    <h1>Video</h1>
  </center>
  <p align="center">
    <iframe width="660" height="395" src="https://www.youtube.com/embed/ir711NZOS2Q" frameborder="0"
      allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
  </p>

  <!--
  <table align=center width=800px>
    <br>
    <tr>
      <center>
        <span style="font-size:28px"><a href=''>[Slides]</a>
        </span>
      </center>
    </tr>
  </table>
  <hr>
  -->

  <!--
  <center>
    <h1>Code</h1>
  </center>

  <table align=center width=420px>
    <center>
      <tr>
        <td>
        </td>
      </tr>
    </center>
  </table>
  <table align=center width=400px>
    <tr>
      <td align=center width=400px>
        <center>
      <td><img class="round" style="width:450px" src="./resources/method_diagram.png" /></td>
      </center>
      </td>
    </tr>
  </table>
  <table align=center width=850px>
    <center>
      <tr>
        <td>
          Short description if wanted
        </td>
      </tr>
    </center>
  </table>
  <table align=center width=800px>
    <br>
    <tr>
      <center>
        <span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/webpage-template'>[GitHub]</a>
      </center>
      </span>
  </table>
  <br>
  <hr>
  -->

  <table align=center width=450px>
    <center>
      <h1>Paper</h1>
    </center>
    <tr>
      <td><a href="https://arxiv.org/pdf/2403.10677"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png" /></a></td>
      <td><span style="font-size:14pt">A. Ziegler, K. Vetter, T. Gossard, J. Tebbe, A. Zell.<br>
          <b><a href="https://arxiv.org/pdf/2403.10677">Spiking Neural Networks for Fast-Moving Object Detection on Neuromorphic Hardware Devices Using an Event-Based Camera.</a></b><br>
          <!--In Conference, 20XX.<br>-->
          (hosted on <a href="https://arxiv.org/pdf/2403.10677">ArXiv</a>)<br>
          <!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
          <span style="font-size:4pt"><a href=""><br></a>
          </span>
      </td>
    </tr>
  </table>
  <br>

  <table align=center width=600px>
    <tr>
      <td><span style="font-size:14pt">
          <center>
            <a href="./resources/bibtex.txt">[Bibtex]</a>
          </center>
      </td>
    </tr>
  </table>

  <hr>
  <br>

  <table align=center width=900px>
    <tr>
      <td width=400px>
        <left>
          <center>
            <h1>Acknowledgements</h1>
          </center>
          This research was partially funded by <a href="https://ai.sony">Sony AI</a>.
        </left>
      </td>
    </tr>
  </table>

  <br>
</body>

</html>
